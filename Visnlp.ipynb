{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64cf980",
   "metadata": {},
   "source": [
    "# VISNLP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc4b179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This plain abdominal radiograph of an about 1-month-old male infant shows markedly distended stomach.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import joblib\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch import tensor\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "class VisualNLPCustomDataset(Dataset):\n",
    "    def __init__(self,dataframe,image_path):\n",
    "        self.data = joblib.load(dataframe)\n",
    "        self.image_path = image_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        image_path = os.path.join(self.image_path, row['ImagePath'], row['Filename'])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        transform = transforms.ToTensor()\n",
    "        image_tensor = transform(image)\n",
    "        \n",
    "        return image_tensor, row['Caption']\n",
    "    \n",
    "train = VisualNLPCustomDataset('../Dataset/Train_Data.pkl','../Data/Training/01.원천데이터')\n",
    "image_tensor, text = train[0] # 3,512,512 (정규화된 Tensor Image: 소아 복부 X_ray : RGB), Caption: 'This plain abdominal radiograph reveals marked..'\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e82e6b",
   "metadata": {},
   "source": [
    "# VISUAL+NLP DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d52e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512, 512])\n",
      "('This plain abdominal radiograph of an about 1-month-old male infant shows markedly distended stomach.',)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train,1,False)\n",
    "batch_image_tensor, batch_nlp = next(iter(train_dataloader))\n",
    "print(batch_image_tensor.shape) # (batchsize:3, 3, 512, 512)\n",
    "print(batch_nlp) # (batchsize:3, 3개의 Texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bfcbcf",
   "metadata": {},
   "source": [
    "# Cross Attention - VIS + NLP Integrated Vector 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70820e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches shape: torch.Size([1, 4096, 160])\n",
      "pos_embedding shape: torch.Size([1, 4096, 160])\n"
     ]
    }
   ],
   "source": [
    "from Visnlp import ViTFeatureExtractor, BertFeatureExtractor, CrossAttention, VISNLPEXTRACTOR\n",
    "\n",
    "ex = BertFeatureExtractor()\n",
    "vex = ViTFeatureExtractor(512,512,patch_size=8,embed_dim=160,num_heads=4,depth=8,in_channels=3)\n",
    "vex(batch_image_tensor)\n",
    "# visnlpextractor = VISNLPEXTRACTOR(512,512,8,312,4,12)\n",
    "# visnlpextractor(batch_image_tensor, batch_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a764d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FirstProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
